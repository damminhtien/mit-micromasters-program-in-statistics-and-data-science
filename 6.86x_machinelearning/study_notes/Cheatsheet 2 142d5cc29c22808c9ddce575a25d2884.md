# Cheatsheet 2

### **Machine Learning Comprehensive Cheatsheet**

### *Key Theories, Formulas, and Concepts for Core Machine Learning Problems*

---

## **1. Support Vector Machines (SVM) & Maximum Margin Classifier**

### **1.1 Maximum Margin Classifier**

- **Objective: $\min_{\theta, \theta_0} \frac{1}{2} \|\theta\|^2 \quad \text{subject to} \quad y^{(i)} (\theta \cdot x^{(i)} + \theta_0) \geq 1 \quad \forall i = 1, \ldots, n$**
    - $\theta$: Weight vector
    - $\theta_0$: Bias term
    - $y^{(i)}$: Labels 1 or -1
    - $x^{(i)}$: Feature vectors
- **Conditions for Solution:**
    - **True:** Solution exists **if and only if** data is linearly separable.
- **Properties:**
    - **Maximum Margin:** The classifier maximizes the margin $M = \frac{1}{\|\theta\|}$ between classes.
    - **Norm Minimization:** $\|\theta\|$ is minimized to maximize the margin.
    - **Classifier Comparison:** For any classifier $(\theta', \theta'_0)$ correctly classifying all data, $\|\theta'\| \geq \|\hat{\theta}\|$, where $(\hat{\theta}, \hat{\theta}_0)$ is the maximum margin classifier.

### **1.2 Hinge Loss**

- **Formula: $\text{Hinge Loss}_i = \max(0, 1 - y^{(i)} (\theta \cdot x^{(i)} + \theta_0))$**
- **Interpretation:**
    - **Zero Loss:** Correct classification with margin \(\geq 1\).
    - **Positive Loss:** Misclassification or margin violation.

## **2. Kernel Methods**

### **2.1 Common Kernel Functions**

- **Linear Kernel: $K(x, x') = x \cdot x'$**
- **Polynomial Kernel: $K(x, x') = \left(1 + \frac{x \cdot x'}{2}\right)^d \quad \text{for } d = 1, 2, 3$**
    - **Examples:**
        - $K_1(x, x') = 1 + \frac{x \cdot x'}{2}$
        - $K_2(x, x') = \left(1 + \frac{x \cdot x'}{2}\right)^2$
        - $K_3(x, x') = \left(1 + \frac{x \cdot x'}{2}\right)^3$
- **Gaussian (RBF) Kernel: $K_g(x, x') = \exp\left(\frac{(x \cdot x')^2}{2}\right)$**

### **2.2 Kernel Trick**

- **Purpose:** Compute dot products in a higher-dimensional feature space without explicit mapping.
- **Dual Formulation for SVM: $\max_{\alpha} \sum_{i=1}^n \alpha_i - \frac{1}{2} \sum_{i,j=1}^n \alpha_i \alpha_j y^{(i)} y^{(j)} K(x^{(i)}, x^{(j)})$**
    - **Constraints: $\alpha_i \geq 0 \quad \forall i, \quad \text{and} \quad \sum_{i=1}^n \alpha_i y^{(i)} = 0$**
- **Decision Function: $f(x) = \text{sign}\left(\sum_{i=1}^n \alpha_i y^{(i)} K(x^{(i)}, x) + \theta_0\right)$**

## **3. Neural Networks**

### **3.1 Two-Layer Feed-Forward Neural Network with ReLU Units**

- **Architecture:**
    - **Input Layer:** $x \in \mathbb{R}^2$
    - **Hidden Layer:** Two ReLU units ($f_1, f_2$), no bias.
    - **Output Layer:** Linear combination $y = W_1 f_1 + W_2 f_2 + W_0$, followed by a sign activation.
- **ReLU Activation Function: $f(z) = \max(0, z)$**
- **Mapping Input Regions:**
    - **Classifier Lines:** $z_1 = w_1 \cdot x = 0$, $z_2 = w_2 \cdot x = 0$
    - **Defined Regions:**
        - **I:** $z_1 > 0$, $z_2 > 0 \rightarrow (f_1 > 0, f_2 > 0)$
        - **II:** $z_1 > 0, z_2 \leq 0 \rightarrow (f_1 > 0, f_2 = 0)$
        - **III:** $z_1 \leq 0, z_2 \leq 0 \rightarrow (f_1 = 0, f_2 = 0)$
        - **IV:** $z_1 \leq 0, z_2 > 0 \rightarrow (f_1 = 0, f_2 > 0)$

### **3.2 Weight Initialization**

- **Small Weights:**
    - Prevent saturation of activation functions (e.g., sigmoid near linearity).
    - Maintain gradient flow during training.
- **Large Weights:**
    - Activation functions may behave like binary functions (e.g., sign function).
    - Risk of vanishing/exploding gradients.

### **3.3 Convolutional vs. Fully Connected Layers**

- **Convolutional Layers:**
    - **Weight Sharing:** Same filter applied across different spatial locations.
    - **Advantages:** Fewer parameters, spatial invariance.
- **Fully Connected Layers:**
    - **Independent Weights:** Each input unit connects to every output unit.
    - **Disadvantages:** More parameters, limited spatial generalization.

## **4. Recurrent Neural Networks (RNN)**

### **4.1 Simple RNN Architecture for Classification**

- **Structure: $s_t = \text{ReLU}(W^{s,s} s_{t-1} + W^{s,x} x_t)$; $y = \text{sign}(W^{s,y} s_T + W_0)$**
    - **$s_t$:** Hidden state at time t
    - **$x_t$:** Input vector at time t
    - **$W^{s,s}$:** Recurrent weights
    - **$W^{s,x}$:** Input weights
    - **$W^{s,y}$:** Output weights
    - **$W_0$:** Bias term

### **4.2 Hidden State Dynamics**

- **One-Hot Encoding:**
    - Each word is represented as a vector with a single active element.
    - Example: For vocabulary $V = \{A, B\}$:
        - $A = [1, 0]^T$
        - $B = [0, 1]^T$
- **State Updates:**
    - **Initial State:** $s_0 = [0, 0]^T$
    - **Example Weights: $W^{s,s} = \begin{bmatrix} -1 & 0 \\ 0 & 1 \end{bmatrix}, \quad W^{s,x} = \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix}$**
- **Computation Example:**
    - For a sentence like **ABB**: $s_1 = \text{ReLU}(W^{s,s} s_0 + W^{s,x} x_1) = \text{ReLU}\left(\begin{bmatrix} -1 & 0 \\ 0 & 1 \end{bmatrix} \begin{bmatrix} 0 \\ 0 \end{bmatrix} + \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix} \begin{bmatrix} 1 \\ 0 \end{bmatrix}\right) = \text{ReLU}\left(\begin{bmatrix} 1 \\ 0 \end{bmatrix}\right) = \begin{bmatrix} 1 \\ 0 \end{bmatrix}$
        - Continue updating for each time step.

### **4.3 Classification with RNN**

- **Output Calculation: $y = \text{sign}(W^{s,y} s_T + W_0)$**
    - **Decision Boundary:** Linear combination of final hidden state.
- **Limitations:**
    - **Fixed Hidden Weights:** Limits adaptability; only output layer is trainable.
    - **Representation Power:** Without biases or additional layers, certain patterns may remain inseparable.

## **5. Reinforcement Learning**

### **5.1 Markov Decision Processes (MDP)**

- **Components:**
    - **States (S):** $x, y_1, y_2$
    - **Actions (A):** $a$ (single action)
    - **Transition Probabilities $P(s'|s, a)$:**
        - $P(y_1 | x, a) = 1$
        - $P(y_1 | y_1, a) = p, P(y_2 | y_1, a) = 1 - p$
        - $P(y_2 | y_2, a) = 1$ (absorbing state)
    - **Rewards $R(s, a, s')$:**
        - $R(y_1, a, y_1) = 1$
        - $R(y_1, a, y_2) = 1$
        - $R(s, a, s') = 0$ otherwise
    - **Discount Factor $(\gamma: 0 < \gamma < 1)$**

### **5.2 Value Function & Bellman's Equation**

- **Optimal Value Function $V^*(s)$:**
    
    $V^*(s) = \max_a \sum_{s'} P(s'|s, a) \left[ R(s, a, s') + \gamma V^*(s') \right]$
    
- **Example Computation:**
    - **For $y_1$:**
        - $V^*(y_1) = p (1 + \gamma V^*(y_1)) + (1 - p)(1 + \gamma \cdot 0)$
        - $V^*(y_1) = 1 + p \gamma V^*(y_1)$
        - $V^*(y_1) = \frac{1}{1 - p \gamma}$
- **Optimal Q-Function $Q^*(s, a)$: $Q^*(x, a) = \gamma V^*(y_1) = \frac{\gamma}{1 - p \gamma}$**

## **6. Expectation-Maximization (EM) Algorithm**

### **6.1 Overview**

- **Purpose:** Estimate parameters in models with latent variables (e.g., Gaussian Mixture Models).
- **Steps:**
    1. **Expectation (E-Step):** Calculate responsibilities $\gamma(z_{ik})$ based on current parameters.
    2. **Maximization (M-Step):** Update parameters to maximize the expected log-likelihood.
- **Properties:**
    - **Monotonic Improvement:** Each iteration never decreases the data likelihood.
    - **Initialization Sensitivity:** Different starting points can lead to different local optima.

### **6.2 Gaussian Mixture Models (GMM)**

- **Components:**
    - **Means ($\mu_k$)**
    - **Covariances ($\Sigma_k$)**
    - **Mixing Proportions ($\pi_k$)**
- **EM Steps:**
    - **E-Step:**
    
    $$
    \gamma(z_{ik}) = \frac{\pi_k \mathcal{N}(x_i | \mu_k, \Sigma_k)}{\sum_{j=1}^K \pi_j \mathcal{N}(x_i | \mu_j, \Sigma_j)} 
    $$
    
    - **M-Step:**

$$
\mu_k = \frac{\sum_{i=1}^n \gamma(z_{ik}) x_i}{\sum_{i=1}^n \gamma(z_{ik})}
$$

$$
\Sigma_k = \frac{\sum_{i=1}^n \gamma(z_{ik}) (x_i - \mu_k)(x_i - \mu_k)^T}{\sum_{i=1}^n \gamma(z_{ik})}
$$

$$
\pi_k = \frac{1}{n} \sum_{i=1}^n \gamma(z_{ik})
$$

### **6.3 Key Insights**

- **Handling Degenerate Cases:** Components with $\pi_k = 0$ are effectively removed.
- **Convergence:** EM converges to a local maximum of the likelihood, not necessarily the global maximum.

## **7. Quick Reference Formulas**

### **7.1 SVM & Maximum Margin**

$$
\min_{\theta, \theta_0} \frac{1}{2} \|\theta\|^2 \quad \text{subject to} \quad y^{(i)} (\theta \cdot x^{(i)} + \theta_0) \geq 1 \quad \forall i
$$

$$
\text{Margin} = \frac{1}{\|\theta\|}
$$

$$
\text{Hinge Loss}_i = \max(0, 1 - y^{(i)} (\theta \cdot x^{(i)} + \theta_0))
$$

### **7.2 Kernel Functions**

$$
K_1(x, x') = 1 + \frac{x \cdot x'}{2}
$$

$$
K_2(x, x') = \left(1 + \frac{x \cdot x'}{2}\right)^2
$$

$$
K_3(x, x') = \left(1 + \frac{x \cdot x'}{2}\right)^3
$$

$$
K_g(x, x') = \exp\left(\frac{(x \cdot x')^2}{2}\right)
$$

### **7.3 Neural Network Equations**

- **Hidden State Update: $s_t = \text{ReLU}(W^{s,s} s_{t-1} + W^{s,x} x_t)$**
- **Output: $y = \text{sign}(W^{s,y} s_T + W_0)$**

### **7.4 Bellman's Equation for Value Function**

$V^*(s) = \max_a \sum_{s'} P(s'|s, a) \left[ R(s, a, s') + \gamma V^*(s') \right]$ 

### **7.5 EM Algorithm for GMM**

- **E-Step:**

$$
\gamma(z_{ik}) = \frac{\pi_k \mathcal{N}(x_i | \mu_k, \Sigma_k)}{\sum_{j=1}^K \pi_j \mathcal{N}(x_i | \mu_j, \Sigma_j)} 
$$

- **M-Step:**

$$
\mu_k = \frac{\sum_{i=1}^n \gamma(z_{ik}) x_i}{\sum_{i=1}^n \gamma(z_{ik})}
$$

$$
\Sigma_k = \frac{\sum_{i=1}^n \gamma(z_{ik}) (x_i - \mu_k)(x_i - \mu_k)^T}{\sum_{i=1}^n \gamma(z_{ik})}
$$

$$
\pi_k = \frac{1}{n} \sum_{i=1}^n \gamma(z_{ik})
$$

## **8. Notation Guidelines**

- **Vectors:** Bold lowercase letters, e.g., $\mathbf{w}$, $\mathbf{x}$
- **Matrices:** Bold uppercase letters, e.g., $\mathbf{W}$, $\mathbf{X}$
- **Dot Product:** $\mathbf{w} \cdot \mathbf{x}$ or $\mathbf{w}^T \mathbf{x}$
- **Norm:** $\|\mathbf{w}\|$ (Euclidean norm)
- **Activation Functions:**
    - **ReLU:** $\text{ReLU}(z) = \max(0, z)$
    - **Sign: $\text{sign}(z) = \begin{cases}
    1 & \text{if } z \geq 0 \\
    -1 & \text{if } z < 0
    \end{cases}$**
- **Summation:** $\sum_{i=1}^n$

## **9. Common Concepts & Tips**

### **9.1 Linear Separability**

- **Definition:** Data can be perfectly divided by a linear hyperplane.
- **SVM Applicability:** Maximum margin classifiers require linear separability for hard-margin SVM.

### **9.2 Kernel Selection**

- **Polynomial Kernels:** Capture feature interactions up to degree d.
- **Gaussian (RBF) Kernels:** Handle non-linear, smooth decision boundaries; parameter $\sigma$ controls the kernel width.

### **9.3 Neural Network Initialization**

- **Small Weights:** Prevent activation saturation; maintain gradient flow.
- **Large Weights:** Risk of activation functions behaving like binary functions; may cause vanishing/exploding gradients.

### **9.4 Recurrent Neural Networks (RNN)**

- **Hidden States:** Carry information across time steps.
- **Activation Functions:** ReLU introduces sparsity; helps mitigate vanishing gradients.

### **9.5 EM Algorithm**

- **Convergence:** Guarantees non-decreasing likelihood; sensitive to initial parameters.
- **Component Collapse:** Components with zero mixing proportions are effectively removed from the model.

### **9.6 Value Functions in Reinforcement Learning**

- **$V^*(s)$:** Maximum expected discounted reward starting from state s.
- **$Q^*(s, a)$:** Maximum expected discounted reward starting from state s and taking action a.

---

## **10. Example Problem Insights**

### **Problem 1: SVM & Maximum Margin**

- **Existence of Solution:** Only if data is linearly separable.
- **Classifier Norms:** Maximum margin classifier has the smallest norm among all classifiers that correctly classify the data.

### **Problem 2: Kernel Methods**

- **Kernel Identification:** Each kernel function corresponds to a unique feature space transformation and affects the shape of the decision boundary.

### **Problem 3: Reinforcement Learning (MDP)**

- **Value Function Calculation: $V^*(y_1) = \frac{1}{1 - \gamma p}$**
- **Q-Function Relation: $Q^*(x, a) = \frac{\gamma}{1 - \gamma p}$**

### **Problem 4: Recurrent Neural Networks (RNN)**

- **Hidden State Mapping:** Specific user-item pairs map to unique activation points based on weight configurations.
- **Weight Updates:** Only weights involved in the active path during a misclassification are updated.
- **Classification Limitation:** Linear classifiers on fixed hidden states may not separate all examples without additional layers or bias terms.

### **Problem 5: Expectation-Maximization (EM)**

- **Mixture Models:** EM iteratively estimates component parameters, ensuring likelihood does not decrease.
- **Parameter Estimation:** Even with identical initial means and variances, mixing proportions can evolve based on data distribution.

## **11. Summary**

This cheatsheet consolidates essential machine learning concepts essential for solving classification, regression, and clustering problems. Key areas include:

- **Support Vector Machines (SVM):** Understanding maximum margin classifiers, hinge loss, and conditions for linear separability.
- **Kernel Methods:** Leveraging different kernel functions to handle non-linear data, employing the kernel trick in dual formulations.
- **Neural Networks:** Designing two-layer feed-forward networks with ReLU activations, weight initialization strategies, and differentiating between convolutional and fully connected layers.
- **Recurrent Neural Networks (RNN):** Managing sequential data through hidden state dynamics and understanding classification limitations.
- **Reinforcement Learning:** Utilizing Markov Decision Processes (MDP), computing optimal value and Q-functions using Bellman's equation.
- **Expectation-Maximization (EM) Algorithm:** Iteratively estimating parameters in models with latent variables like Gaussian Mixture Models, ensuring likelihood improvement.

**Key Takeaways:**

- **Optimization & Initialization:** Proper weight initialization and understanding optimization constraints are crucial for effective model training.
- **Model Selection:** Choosing appropriate kernels and network architectures significantly impacts model performance and generalization.
- **Algorithm Behavior:** Understanding theoretical properties of algorithms like EM and gradient descent aids in diagnosing and improving model training processes.